{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71a5334",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d489bd",
   "metadata": {},
   "source": [
    "###### Importing Image Data Generator Library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08054b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773c383",
   "metadata": {},
   "source": [
    "###### Configure Image datagenerator class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e0de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting parameter for image data agumentationto the training data\n",
    "train_datagen=ImageDataGenerator(rescale=1./225,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "#image data agumenatation to test dataset\n",
    "test_datagen=ImageDataGenerator(rescale=1./225)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35939d05",
   "metadata": {},
   "source": [
    "###### Applying ImageDataGenerator Functionality to train and test Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba0eb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15341 images belonging to 6 classes.\n",
      "Found 6825 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "#performing data agumentation to train the dataset\n",
    "x_train=train_datagen.flow_from_directory(directory='C:/Users/Saipriya/OneDrive/Desktop/data/train',target_size=(64,64),batch_size=32,class_mode='categorical')\n",
    "#performing agumentation to test the dataset\n",
    "x_test=test_datagen.flow_from_directory(directory='C:/Users/Saipriya/OneDrive/Desktop/data/test',target_size=(64,64),batch_size=32,class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eff2ec",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be83444",
   "metadata": {},
   "source": [
    "###### Importing Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2396027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6293b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f75ce0e",
   "metadata": {},
   "source": [
    "###### Adding CNN Layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a2e2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding model layer\n",
    "model.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd5b67",
   "metadata": {},
   "source": [
    "###### Adding Dense Layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01609dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                200736    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 211,078\n",
      "Trainable params: 211,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(32))\n",
    "model.add(Dense(6,activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fed493",
   "metadata": {},
   "source": [
    "###### Configuring the learning process\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16ccd7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7035c34b",
   "metadata": {},
   "source": [
    "###### Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff8f0086",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saipriya\\AppData\\Local\\Temp\\ipykernel_16540\\53529210.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=x_train,steps_per_epoch = len(x_train), epochs=10, validation_data=x_test,validation_steps = len(x_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "480/480 [==============================] - 90s 184ms/step - loss: 0.7718 - accuracy: 0.7376 - val_loss: 0.4899 - val_accuracy: 0.8243\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 108s 225ms/step - loss: 0.2681 - accuracy: 0.9218 - val_loss: 0.4358 - val_accuracy: 0.8598\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 93s 194ms/step - loss: 0.2177 - accuracy: 0.9355 - val_loss: 0.3286 - val_accuracy: 0.9116\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 84s 175ms/step - loss: 0.1840 - accuracy: 0.9469 - val_loss: 0.3407 - val_accuracy: 0.8919\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 101s 210ms/step - loss: 0.1577 - accuracy: 0.9529 - val_loss: 0.3456 - val_accuracy: 0.9034\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 96s 200ms/step - loss: 0.1411 - accuracy: 0.9576 - val_loss: 0.4097 - val_accuracy: 0.8983\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 83s 173ms/step - loss: 0.1204 - accuracy: 0.9621 - val_loss: 0.4474 - val_accuracy: 0.8908\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 79s 165ms/step - loss: 0.1196 - accuracy: 0.9643 - val_loss: 0.3226 - val_accuracy: 0.9197\n",
      "Epoch 9/10\n",
      "480/480 [==============================] - 60s 126ms/step - loss: 0.1050 - accuracy: 0.9685 - val_loss: 0.4323 - val_accuracy: 0.8963\n",
      "Epoch 10/10\n",
      "480/480 [==============================] - 68s 141ms/step - loss: 0.1028 - accuracy: 0.9681 - val_loss: 0.3876 - val_accuracy: 0.9127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208f82497c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=x_train,steps_per_epoch = len(x_train), epochs=10, validation_data=x_test,validation_steps = len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124072d2",
   "metadata": {},
   "source": [
    "###### Saving the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd127600",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ECG.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a8bb9",
   "metadata": {},
   "source": [
    "###### Test the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "821a1492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "model=load_model(\"ECG.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc02b0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = image.load_img(\"C:/Users/Saipriya/OneDrive/Desktop/data/test/Premature Atrial Contraction/fig_26.png\",target_size=(64,64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x,axis=0)\n",
    "pred = model.predict(x)\n",
    "y_pred = np.argmax(pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50253b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Premature Atrial Contraction'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=['left Bundle Branch block','Normal','Premature Atrial Contraction','Premature Ventricular Contraction','Right Bundle Branch Block','Ventricular Fibrillation']\n",
    "result = str(index[y_pred])\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
